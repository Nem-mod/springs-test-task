{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Задача: система має відповідати на питання користувача по контенту документу.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25b7c8b6ac969b63"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Документи і приклади запитань:\n",
    "1. https://assets.ctfassets.net/fzn2n1nzq965/5Qj1NdQFtWO3rIE4WhAVl9/21202f8455f5a877444f91c1b48baf6e/stripe-2022-update.pdf\n",
    "- Where are the top startups located?\n",
    "2. https://www.coffeeb.com/media/77/c5/ab/1660233188/CoffeeB_Manual%20Gl\n",
    "obe_EN_10.08.2022.pdf\n",
    "- How can I resolve the issue of my coffee being trapped in the machine?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2acc20bda7848e53"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Project stack\n",
    "llama-index => 0.9\n",
    "pypdf\n",
    "chromaDB"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1ea41d17ccd7cc7"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.10.15-py3-none-any.whl (5.6 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
      "     -------------------------------------- 286.1/286.1 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "     -------------------------------------- 525.5/525.5 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting llama-index-agent-openai<0.2.0,>=0.1.4\n",
      "  Downloading llama_index_agent_openai-0.1.5-py3-none-any.whl (12 kB)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2\n",
      "  Downloading llama_index_cli-0.1.7-py3-none-any.whl (25 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.15\n",
      "  Downloading llama_index_core-0.10.15-py3-none-any.whl (15.3 MB)\n",
      "     ---------------------------------------- 15.3/15.3 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5\n",
      "  Downloading llama_index_embeddings_openai-0.1.6-py3-none-any.whl (6.0 kB)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.1.3-py3-none-any.whl (6.6 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.5\n",
      "  Downloading llama_index_llms_openai-0.1.7-py3-none-any.whl (9.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl (5.8 kB)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3\n",
      "  Downloading llama_index_program_openai-0.1.4-py3-none-any.whl (4.1 kB)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4\n",
      "  Downloading llama_index_readers_file-0.1.6-py3-none-any.whl (34 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2\n",
      "  Downloading llama_index_readers_llama_parse-0.1.3-py3-none-any.whl (2.5 kB)\n",
      "Collecting build>=1.0.3\n",
      "  Downloading build-1.1.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests>=2.28 in d:\\anime\\springtest\\lib\\site-packages (from chromadb) (2.31.0)\n",
      "Collecting pydantic>=1.9\n",
      "  Downloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "     -------------------------------------- 395.2/395.2 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting chroma-hnswlib==0.7.3\n",
      "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-win_amd64.whl (151 kB)\n",
      "     -------------------------------------- 151.6/151.6 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting fastapi>=0.95.2\n",
      "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "     ---------------------------------------- 92.1/92.1 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting uvicorn[standard]>=0.18.3\n",
      "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 60.8/60.8 kB ? eta 0:00:00\n",
      "Collecting numpy>=1.22.5\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "     ---------------------------------------- 15.8/15.8 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting posthog>=2.4.0\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 41.3/41.3 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4.5.0\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Collecting pulsar-client>=3.1.0\n",
      "  Downloading pulsar_client-3.4.0-cp311-cp311-win_amd64.whl (3.4 MB)\n",
      "     ---------------------------------------- 3.4/3.4 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting onnxruntime>=1.14.1\n",
      "  Downloading onnxruntime-1.17.1-cp311-cp311-win_amd64.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Downloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.4/58.4 kB ? eta 0:00:00\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0\n",
      "  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
      "     -------------------------------------- 105.7/105.7 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting tokenizers>=0.13.2\n",
      "  Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting pypika>=0.48.9\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "     ---------------------------------------- 67.3/67.3 kB 1.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tqdm>=4.65.0\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.3/78.3 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: overrides>=7.3.1 in d:\\anime\\springtest\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-6.1.2-py3-none-any.whl (34 kB)\n",
      "Collecting grpcio>=1.58.0\n",
      "  Downloading grpcio-1.62.0-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "     ---------------------------------------- 3.8/3.8 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting bcrypt>=4.0.1\n",
      "  Downloading bcrypt-4.1.2-cp39-abi3-win_amd64.whl (158 kB)\n",
      "     -------------------------------------- 158.3/158.3 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting typer>=0.9.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.9/45.9 kB ? eta 0:00:00\n",
      "Collecting kubernetes>=28.1.0\n",
      "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting tenacity>=8.2.3\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in d:\\anime\\springtest\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1\n",
      "  Downloading mmh3-4.1.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Collecting orjson>=3.9.12\n",
      "  Downloading orjson-3.9.15-cp311-none-win_amd64.whl (136 kB)\n",
      "     -------------------------------------- 136.0/136.0 kB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=19.0 in d:\\anime\\springtest\\lib\\site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Collecting pyproject_hooks\n",
      "  Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: colorama in d:\\anime\\springtest\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting starlette<0.37.0,>=0.36.3\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 71.5/71.5 kB 3.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=14.05.14 in d:\\anime\\springtest\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\anime\\springtest\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\anime\\springtest\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1\n",
      "  Downloading google_auth-2.28.1-py2.py3-none-any.whl (186 kB)\n",
      "     -------------------------------------- 186.9/186.9 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\anime\\springtest\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
      "Collecting requests-oauthlib\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.2.2\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3>=1.24.2 in d:\\anime\\springtest\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Collecting llama-index-vector-stores-chroma<0.2.0,>=0.1.1\n",
      "  Downloading llama_index_vector_stores_chroma-0.1.5-py3-none-any.whl (4.7 kB)\n",
      "Collecting SQLAlchemy[asyncio]>=1.4.49\n",
      "  Downloading SQLAlchemy-2.0.28-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting aiohttp<4.0.0,>=3.8.6\n",
      "  Downloading aiohttp-3.9.3-cp311-cp311-win_amd64.whl (365 kB)\n",
      "     -------------------------------------- 365.3/365.3 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting dataclasses-json\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting deprecated>=1.2.9.3\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "     -------------------------------------- 170.9/170.9 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: httpx in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (0.27.0)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.13\n",
      "  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
      "     -------------------------------------- 108.0/108.0 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.15->llama-index) (1.6.0)\n",
      "Collecting networkx>=3.0\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting nltk<4.0.0,>=3.8.1\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting openai>=1.1.0\n",
      "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "     -------------------------------------- 227.4/227.4 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.1-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "     ---------------------------------------- 11.6/11.6 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting pillow>=9.0.0\n",
      "  Downloading pillow-10.2.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting tiktoken>=0.3.3\n",
      "  Downloading tiktoken-0.6.0-cp311-cp311-win_amd64.whl (798 kB)\n",
      "     -------------------------------------- 798.7/798.7 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting typing-inspect>=0.8.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Collecting bs4<0.0.3,>=0.0.2\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Collecting pymupdf<2.0.0,>=1.23.21\n",
      "  Downloading PyMuPDF-1.23.26-cp311-none-win_amd64.whl (3.4 MB)\n",
      "     ---------------------------------------- 3.4/3.4 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting llama-parse<0.4.0,>=0.3.3\n",
      "  Downloading llama_parse-0.3.5-py3-none-any.whl (7.7 kB)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.0/46.0 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting flatbuffers\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "     -------------------------------------- 413.4/413.4 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "     ---------------------------------------- 5.7/5.7 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata<7.0,>=6.0\n",
      "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Collecting googleapis-common-protos~=1.52\n",
      "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "     -------------------------------------- 228.7/228.7 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.23.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
      "Collecting opentelemetry-proto==1.23.0\n",
      "  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 50.8/50.8 kB ? eta 0:00:00\n",
      "Collecting opentelemetry-instrumentation-asgi==0.44b0\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
      "Collecting opentelemetry-instrumentation==0.44b0\n",
      "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.44b0\n",
      "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
      "Collecting opentelemetry-util-http==0.44b0\n",
      "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in d:\\anime\\springtest\\lib\\site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (65.5.1)\n",
      "Collecting wrapt<2.0.0,>=1.0.0\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Collecting asgiref~=3.0\n",
      "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Collecting monotonic>=1.5\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.16.3\n",
      "  Downloading pydantic_core-2.16.3-cp311-none-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anime\\springtest\\lib\\site-packages (from requests>=2.28->chromadb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anime\\springtest\\lib\\site-packages (from requests>=2.28->chromadb) (3.6)\n",
      "Collecting huggingface_hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.21.3-py3-none-any.whl (346 kB)\n",
      "     -------------------------------------- 346.2/346.2 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting click<9.0.0,>=7.1.1\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 97.9/97.9 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h11>=0.8 in d:\\anime\\springtest\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Collecting httptools>=0.5.0\n",
      "  Downloading httptools-0.6.1-cp311-cp311-win_amd64.whl (55 kB)\n",
      "     ---------------------------------------- 55.4/55.4 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-0.21.0-cp311-none-win_amd64.whl (280 kB)\n",
      "     -------------------------------------- 280.1/280.1 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-12.0-cp311-cp311-win_amd64.whl (124 kB)\n",
      "     -------------------------------------- 125.0/125.0 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anime\\springtest\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.15->llama-index) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "     ---------------------------------------- 50.5/50.5 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
      "     ---------------------------------------- 76.7/76.7 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anime\\springtest\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     -------------------------------------- 181.3/181.3 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Requirement already satisfied: anyio in d:\\anime\\springtest\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.15->llama-index) (4.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anime\\springtest\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.15->llama-index) (1.0.4)\n",
      "Requirement already satisfied: sniffio in d:\\anime\\springtest\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.15->llama-index) (1.3.1)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "     -------------------------------------- 302.2/302.2 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2023.12.25-cp311-cp311-win_amd64.whl (269 kB)\n",
      "     -------------------------------------- 269.5/269.5 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting PyMuPDFb==1.23.22\n",
      "  Downloading PyMuPDFb-1.23.22-py3-none-win_amd64.whl (24.5 MB)\n",
      "     ---------------------------------------- 24.5/24.5 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-win_amd64.whl (292 kB)\n",
      "     -------------------------------------- 292.8/292.8 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 86.8/86.8 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.4/49.4 kB ? eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "     -------------------------------------- 505.5/505.5 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "     -------------------------------------- 345.4/345.4 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     -------------------------------------- 536.2/536.2 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 95.2/95.2 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "     ---------------------------------------- 84.9/84.9 kB 2.4 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53836 sha256=2954d08d17e44fe4814381e77889ed3643927971d9ab9e3da0186c060e44268d\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\da\\b1\\64\\178bd739d19ac4e7b567619cde8454c523f972963ced4d48c4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pytz, pyreadline3, pypika, mpmath, monotonic, mmh3, flatbuffers, dirtyjson, zipp, wrapt, websockets, tzdata, typing-extensions, tqdm, tenacity, sympy, regex, python-dotenv, pyproject_hooks, pypdf, PyMuPDFb, pyasn1, pulsar-client, protobuf, pillow, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, oauthlib, numpy, networkx, mypy-extensions, multidict, marshmallow, joblib, importlib-resources, humanfriendly, httptools, grpcio, greenlet, fsspec, frozenlist, filelock, distro, click, cachetools, bcrypt, backoff, asgiref, annotated-types, yarl, watchfiles, uvicorn, typing-inspect, typer, tiktoken, starlette, SQLAlchemy, rsa, requests-oauthlib, pymupdf, pydantic-core, pyasn1-modules, posthog, pandas, opentelemetry-proto, nltk, importlib-metadata, huggingface_hub, googleapis-common-protos, deprecated, coloredlogs, chroma-hnswlib, build, bs4, aiosignal, tokenizers, pydantic, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, google-auth, dataclasses-json, aiohttp, opentelemetry-sdk, opentelemetry-instrumentation, openai, llamaindex-py-client, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, llama-index-legacy, llama-index-core, opentelemetry-instrumentation-fastapi, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-agent-openai, chromadb, llama-index-vector-stores-chroma, llama-index-program-openai, llama-index-question-gen-openai, llama-index-cli, llama-index\n",
      "Successfully installed PyMuPDFb-1.23.22 SQLAlchemy-2.0.28 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 asgiref-3.7.2 backoff-2.2.1 bcrypt-4.1.2 bs4-0.0.2 build-1.1.1 cachetools-5.3.3 chroma-hnswlib-0.7.3 chromadb-0.4.24 click-8.1.7 coloredlogs-15.0.1 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 fastapi-0.110.0 filelock-3.13.1 flatbuffers-23.5.26 frozenlist-1.4.1 fsspec-2024.2.0 google-auth-2.28.1 googleapis-common-protos-1.62.0 greenlet-3.0.3 grpcio-1.62.0 httptools-0.6.1 huggingface_hub-0.21.3 humanfriendly-10.0 importlib-metadata-6.11.0 importlib-resources-6.1.2 joblib-1.3.2 kubernetes-29.0.0 llama-index-0.10.15 llama-index-agent-openai-0.1.5 llama-index-cli-0.1.7 llama-index-core-0.10.15 llama-index-embeddings-openai-0.1.6 llama-index-indices-managed-llama-cloud-0.1.3 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.7 llama-index-multi-modal-llms-openai-0.1.4 llama-index-program-openai-0.1.4 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.6 llama-index-readers-llama-parse-0.1.3 llama-index-vector-stores-chroma-0.1.5 llama-parse-0.3.5 llamaindex-py-client-0.1.13 marshmallow-3.21.1 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 multidict-6.0.5 mypy-extensions-1.0.0 networkx-3.2.1 nltk-3.8.1 numpy-1.26.4 oauthlib-3.2.2 onnxruntime-1.17.1 openai-1.13.3 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-instrumentation-asgi-0.44b0 opentelemetry-instrumentation-fastapi-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 opentelemetry-util-http-0.44b0 orjson-3.9.15 pandas-2.2.1 pillow-10.2.0 posthog-3.5.0 protobuf-4.25.3 pulsar-client-3.4.0 pyasn1-0.5.1 pyasn1-modules-0.3.0 pydantic-2.6.3 pydantic-core-2.16.3 pymupdf-1.23.26 pypdf-4.1.0 pypika-0.48.9 pyproject_hooks-1.0.0 pyreadline3-3.4.1 python-dotenv-1.0.1 pytz-2024.1 regex-2023.12.25 requests-oauthlib-1.3.1 rsa-4.9 starlette-0.36.3 sympy-1.12 tenacity-8.2.3 tiktoken-0.6.0 tokenizers-0.15.2 tqdm-4.66.2 typer-0.9.0 typing-extensions-4.10.0 typing-inspect-0.9.0 tzdata-2024.1 uvicorn-0.27.1 watchfiles-0.21.0 websockets-12.0 wrapt-1.16.0 yarl-1.9.4 zipp-3.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index pypdf chromadb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T11:18:38.852768300Z"
    }
   },
   "id": "51b7c46c07cdc63f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-vector-stores-chroma in d:\\anime\\springtest\\lib\\site-packages (0.1.5)\n",
      "Requirement already satisfied: chromadb<0.5.0,>=0.4.22 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-vector-stores-chroma) (0.4.24)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-vector-stores-chroma) (0.10.15)\n",
      "Requirement already satisfied: onnxruntime<2.0.0,>=1.17.0 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-vector-stores-chroma) (1.17.1)\n",
      "Requirement already satisfied: tokenizers<0.16.0,>=0.15.1 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-vector-stores-chroma) (0.15.2)\n",
      "Requirement already satisfied: build>=1.0.3 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.1.1)\n",
      "Requirement already satisfied: requests>=2.28 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (2.6.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.110.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.22.5 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (4.10.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (3.4.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.23.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (4.66.2)\n",
      "Requirement already satisfied: overrides>=7.3.1 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (6.1.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.62.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (4.1.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (29.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in d:\\anime\\springtest\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (3.9.15)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2024.2.0)\n",
      "Requirement already satisfied: httpx in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.8.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.13.3)\n",
      "Requirement already satisfied: pandas in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (10.2.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (0.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\anime\\springtest\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (0.9.0)\n",
      "Requirement already satisfied: coloredlogs in d:\\anime\\springtest\\lib\\site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in d:\\anime\\springtest\\lib\\site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma) (23.5.26)\n",
      "Requirement already satisfied: packaging in d:\\anime\\springtest\\lib\\site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma) (23.2)\n",
      "Requirement already satisfied: protobuf in d:\\anime\\springtest\\lib\\site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma) (4.25.3)\n",
      "Requirement already satisfied: sympy in d:\\anime\\springtest\\lib\\site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma) (1.12)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in d:\\anime\\springtest\\lib\\site-packages (from tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma) (0.21.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anime\\springtest\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anime\\springtest\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anime\\springtest\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anime\\springtest\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anime\\springtest\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.9.4)\n",
      "Requirement already satisfied: pyproject_hooks in d:\\anime\\springtest\\lib\\site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.0.0)\n",
      "Requirement already satisfied: colorama in d:\\anime\\springtest\\lib\\site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.4.6)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in d:\\anime\\springtest\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.16.0)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in d:\\anime\\springtest\\lib\\site-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.36.3)\n",
      "Requirement already satisfied: filelock in d:\\anime\\springtest\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma) (3.13.1)\n",
      "Requirement already satisfied: certifi>=14.05.14 in d:\\anime\\springtest\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\anime\\springtest\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\anime\\springtest\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in d:\\anime\\springtest\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (2.28.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\anime\\springtest\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in d:\\anime\\springtest\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in d:\\anime\\springtest\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in d:\\anime\\springtest\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (2.2.1)\n",
      "Requirement already satisfied: anyio in d:\\anime\\springtest\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (4.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anime\\springtest\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.0.4)\n",
      "Requirement already satisfied: idna in d:\\anime\\springtest\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.6)\n",
      "Requirement already satisfied: sniffio in d:\\anime\\springtest\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anime\\springtest\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (0.14.0)\n",
      "Requirement already satisfied: click in d:\\anime\\springtest\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\anime\\springtest\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anime\\springtest\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anime\\springtest\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.9.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in d:\\anime\\springtest\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (6.11.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in d:\\anime\\springtest\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.62.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in d:\\anime\\springtest\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.23.0 in d:\\anime\\springtest\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in d:\\anime\\springtest\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in d:\\anime\\springtest\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in d:\\anime\\springtest\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.44b0 in d:\\anime\\springtest\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.44b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in d:\\anime\\springtest\\lib\\site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (65.5.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in d:\\anime\\springtest\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (3.7.2)\n",
      "Requirement already satisfied: monotonic>=1.5 in d:\\anime\\springtest\\lib\\site-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in d:\\anime\\springtest\\lib\\site-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\anime\\springtest\\lib\\site-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in d:\\anime\\springtest\\lib\\site-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anime\\springtest\\lib\\site-packages (from requests>=2.28->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\anime\\springtest\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\anime\\springtest\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in d:\\anime\\springtest\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in d:\\anime\\springtest\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in d:\\anime\\springtest\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in d:\\anime\\springtest\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (12.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\anime\\springtest\\lib\\site-packages (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma) (10.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\anime\\springtest\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (3.21.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anime\\springtest\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anime\\springtest\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-chroma) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anime\\springtest\\lib\\site-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma) (1.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anime\\springtest\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anime\\springtest\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anime\\springtest\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (4.9)\n",
      "Requirement already satisfied: pyreadline3 in d:\\anime\\springtest\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma) (3.4.1)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anime\\springtest\\lib\\site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in d:\\anime\\springtest\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma) (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-vector-stores-chroma"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T11:41:51.266019400Z",
     "start_time": "2024-03-05T11:41:40.423747800Z"
    }
   },
   "id": "7f808f7035ba84da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set up openai token"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce31564ef22d70f3"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OPENAI_API_KEY = \"<YOUR_API_KEY>\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:28:42.445756Z",
     "start_time": "2024-03-05T12:28:42.433676200Z"
    }
   },
   "id": "6c66abbf7ceb8d99"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Defining ChatGPT model\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo-16k\"\n",
    "\n",
    "# ChatGPT completion setup\n",
    "OPENAI_COMPLETION_OPTIONS = {\n",
    "    \"temperature\": 0.1,  # respond to accuracy of llm (from 0.1 up to 2)\n",
    "    \"max_tokens\": 1000,  # max amount of tokens that llm is uses \n",
    "    \"top_p\": 1,  # top value of temperature  \n",
    "    \"frequency_penalty\": 0,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"request_timeout\": 60.0,\n",
    "}\n",
    "\n",
    "# Base prompt\n",
    "LLM_BASE_PROMPT = \"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:28:43.017570Z",
     "start_time": "2024-03-05T12:28:42.996881700Z"
    }
   },
   "id": "bb09ea10ef2db535"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create service context"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5fdb7d3464208af"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from llama_index.core.callbacks import LlamaDebugHandler, CallbackManager\n",
    "from llama_index.core import PromptHelper, ServiceContext\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Create instance of llm\n",
    "llm = OpenAI(model=OPENAI_MODEL, temperature=0)\n",
    "# Define embeddings model \n",
    "embed_model = OpenAIEmbedding()\n",
    "\n",
    "# Set up Node parser\n",
    "node_parser = SimpleNodeParser.from_defaults(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "prompt_helper = PromptHelper(\n",
    "    context_window=4096,\n",
    "    num_output=256,\n",
    "    chunk_overlap_ratio=0.1,\n",
    "    chunk_size_limit=None\n",
    ")\n",
    "\n",
    "# Logging\n",
    "llama_debug = LlamaDebugHandler()\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "\n",
    "service_context = {\n",
    "    \"llm\": llm,\n",
    "    \"embed_model\": embed_model,\n",
    "    \"node_parser\": node_parser,\n",
    "    \"prompt_helper\": prompt_helper,\n",
    "    \"system_prompt\": LLM_BASE_PROMPT,\n",
    "    \"callback_manager\": callback_manager\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:28:44.176796100Z",
     "start_time": "2024-03-05T12:28:44.160236500Z"
    }
   },
   "id": "a9b40cc925d76e59"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create client and a new collection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "694b0daa7888eb15"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_CBEventType.EMBEDDING ->  1.417562 seconds\n",
      "**********\n",
      "**********\n",
      "Trace: index_construction\n",
      "    |_CBEventType.EMBEDDING ->  0.940385 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "import chromadb\n",
    "\n",
    "db2 = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "chroma_stripe_collection = db2.get_or_create_collection(\"stripe_embeddings\")\n",
    "chroma_coffeB_collection = db2.get_or_create_collection(\"coffeB_embeddings\")\n",
    "\n",
    "# load documents\n",
    "stripe_documents = SimpleDirectoryReader(\"./data/stripe/\").load_data()\n",
    "coffeB_documents = SimpleDirectoryReader(\"./data/coffeB/\").load_data()\n",
    "\n",
    "# set up ChromaVectorStore and load in data\n",
    "stripe_vector_store = ChromaVectorStore(chroma_collection=chroma_stripe_collection)\n",
    "stripe_storage_context = StorageContext.from_defaults(vector_store=stripe_vector_store)\n",
    "stripe_index = VectorStoreIndex.from_documents(\n",
    "    stripe_documents, **service_context, storage_context=stripe_storage_context\n",
    ")\n",
    "\n",
    "coffeB_vector_store = ChromaVectorStore(chroma_collection=chroma_coffeB_collection)\n",
    "coffeB_storage_context = StorageContext.from_defaults(vector_store=coffeB_vector_store)\n",
    "coffeB_index = VectorStoreIndex.from_documents(\n",
    "    coffeB_documents, **service_context, storage_context=coffeB_storage_context\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:29:17.278403500Z",
     "start_time": "2024-03-05T12:28:45.568071900Z"
    }
   },
   "id": "7d80b6da93b8d090"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating query engine and tools"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c58e2f43c9dbbf8c"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from llama_index.core.selectors import PydanticSingleSelector\n",
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "# initialize tools\n",
    "list_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=stripe_index.as_query_engine(),\n",
    "    description=\"Useful for retrieving information about Stripe.\",\n",
    ")\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=coffeB_index.as_query_engine(),\n",
    "    description=\"Manual for coffeB coffe machine. Retrieves full guidance how to use coffeB machine.\",\n",
    ")\n",
    "\n",
    "# initialize router query engine (single selection, pydantic)\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=PydanticSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        list_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:30:06.098545400Z",
     "start_time": "2024-03-05T12:30:06.084153100Z"
    }
   },
   "id": "111f8ee889eeba7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logining"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ef70b6aaa67ffc8"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:32:11.078975400Z",
     "start_time": "2024-03-05T12:32:11.071920700Z"
    }
   },
   "id": "ef951b570c4e63cd"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.query_engine.router_query_engine:Selecting query engine 0: Stripe is a popular payment processing platform used by many startups, so information about Stripe may provide insights into where top startups are located..\n",
      "Selecting query engine 0: Stripe is a popular payment processing platform used by many startups, so information about Stripe may provide insights into where top startups are located..\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<b>The top startups are located in the Bay Area, Los Angeles, Austin, New York City, Miami, London, Singapore, Paris, Tokyo, and Toronto.</b>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "response = query_engine.query(\"Where are the top startups located?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:32:15.021187400Z",
     "start_time": "2024-03-05T12:32:11.880943400Z"
    }
   },
   "id": "117b395c2abaccda"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.query_engine.router_query_engine:Selecting query engine 0: Stripe is a service that provides information about Stripe, which is relevant to the question 'What is Stripe?'.\n",
      "Selecting query engine 0: Stripe is a service that provides information about Stripe, which is relevant to the question 'What is Stripe?'.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<b>Stripe is a company that focuses on improving online payment processes by addressing deficiencies in the current payment systems. They invest in security measures at various levels of their operations, including data encryption, access controls, and real-time transaction monitoring. Additionally, Stripe prioritizes reliability in their financial operations by holding funds with systematically important financial institutions and continuously monitoring their financial partners and issuers.</b>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"What is stripe?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:35:35.905000300Z",
     "start_time": "2024-03-05T12:35:32.593236800Z"
    }
   },
   "id": "eefc72d4db489793"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.query_engine.router_query_engine:Selecting query engine 0: The question is about the growth of Stripe, and choice (1) is specifically mentioned as useful for retrieving information about Stripe..\n",
      "Selecting query engine 0: The question is about the growth of Stripe, and choice (1) is specifically mentioned as useful for retrieving information about Stripe..\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<b>Stripe experienced significant growth with the number of new businesses joining the platform increasing by 19% in 2022. On average, more than 1,000 new ventures were launched every day. Additionally, Stripe now supports businesses in over 50 countries, with 55% of the businesses that joined last year being based outside of the U.S.</b>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"How stripe is grew up?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:37:51.661081500Z",
     "start_time": "2024-03-05T12:37:48.289427Z"
    }
   },
   "id": "8e720b58e105ccb4"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.query_engine.router_query_engine:Selecting query engine 0: The choice 'Useful for retrieving information about Stripe' is the most relevant to the question 'Tell me about stripe payments'..\n",
      "Selecting query engine 0: The choice 'Useful for retrieving information about Stripe' is the most relevant to the question 'Tell me about stripe payments'..\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<b>Stripe payments have been a focus for improvement, with Stripe working to address deficiencies in online payment processes. They have introduced highly optimized checkout products, such as Payment Element, which have shown to increase revenue for businesses that adopt them. These improvements have significantly reduced checkout times for buyers through various UI adjustments and cross-device optimizations. Additionally, Stripe has updated its \"Remember Me\" functionality to enhance user experience during payments.</b>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me about stripe payments\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:37:56.404116400Z",
     "start_time": "2024-03-05T12:37:53.519097200Z"
    }
   },
   "id": "993f71b3c5911dc5"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.query_engine.router_query_engine:Selecting query engine 0: The question is related to retrieving information about Stripe, which is mentioned in choice (1)..\n",
      "Selecting query engine 0: The question is related to retrieving information about Stripe, which is mentioned in choice (1)..\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<b>There are now more than 100,000 active in-person devices worldwide.</b>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"How much people are active stripe users?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:39:00.457222200Z",
     "start_time": "2024-03-05T12:38:57.841846300Z"
    }
   },
   "id": "d21557db89fac38a"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.query_engine.router_query_engine:Selecting query engine 1: The manual for the coffeB coffee machine provides full guidance on how to use the machine, which includes information on how the coffee machine works..\n",
      "Selecting query engine 1: The manual for the coffeB coffee machine provides full guidance on how to use the machine, which includes information on how the coffee machine works..\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<b>The coffee machine should be placed on a dry, water-proof, and heat-proof surface. It should not be placed directly on marble or wood. The machine needs to be at a specific distance from the sink and open flame. The water tank should be cleaned and filled with cold water, and the power plug should be inserted into an earthed socket. After ensuring the control lever is pressed down, the machine needs to be allowed to warm up for 30 minutes at room temperature. For coffee preparation, one coffee ball is needed for each cup of coffee. The drip tray should be adjusted based on the cup size, and the coffee ball should be placed in the slot before pressing the control lever down to dispense the coffee.</b>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"How coffe machine works?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:40:19.984604400Z",
     "start_time": "2024-03-05T12:40:15.289980600Z"
    }
   },
   "id": "b84bcc100ce36085"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.query_engine.router_query_engine:Selecting query engine 1: The manual for the coffeB coffee machine provides full guidance on how to use the machine, which would include the requirements for using it effectively..\n",
      "Selecting query engine 1: The manual for the coffeB coffee machine provides full guidance on how to use the machine, which would include the requirements for using it effectively..\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<b>Requirements for using coffeB include placing the machine on a dry, horizontal, stable, and flat surface that is resistant to heat and liquids. The machine should not be placed inside a cupboard or on a hot surface. It is important to maintain specific distances from the sink and open flames, and the machine should not be near hobs, gas cookers, or naked flames. Additionally, the power cable should not be accessible to children under 8 years old, and the machine should not be placed on marble surfaces or untreated/oiled woodwork.</b>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"Requirements for using coffeB ?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:42:42.149871200Z",
     "start_time": "2024-03-05T12:42:36.376710500Z"
    }
   },
   "id": "2292bffeeb7095c4"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.query_engine.router_query_engine:Selecting query engine 1: The manual for the coffee machine provides full guidance on how to use the coffee machine, including troubleshooting steps for resolving issues like coffee being trapped in the machine..\n",
      "Selecting query engine 1: The manual for the coffee machine provides full guidance on how to use the coffee machine, including troubleshooting steps for resolving issues like coffee being trapped in the machine..\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<b>Press the control lever down and start the coffee brewing process. As soon as coffee is dispensed, cancel the dispensing process by pressing the coffee key again. If the coffee ball has not been discarded, carefully scrape the coffee ball out of the machine with your finger and/or a spoon. Flush out the pipings if needed. If two balls are stuck, push them down with your finger and remove them.</b>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"How can I resolve the issue of my coffee being trapped in the machine?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T12:42:49.685057700Z",
     "start_time": "2024-03-05T12:42:42.907744700Z"
    }
   },
   "id": "b114e1ede1456d81"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
